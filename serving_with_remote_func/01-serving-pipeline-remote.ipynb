{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "project_name = \"test-serv-with-remote\"\n",
    "# get/create a project and register the data prep and trainer function in it\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=project_name, user_project=False, context=\"./\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"serving-function\"></a>\n",
    "## Create and test the Serving Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from mlrun.frameworks.lgbm import LGBMModelServer\n",
    "\n",
    "import mlrun\n",
    "\n",
    "class MyReggressor(LGBMModelServer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_func_name = \"predict_remote\"\n",
    "fn_remote = mlrun.code_to_function(remote_func_name,\n",
    "                                   project=project_name,\n",
    "                                   kind=\"serving\", \n",
    "                                   image=\"mlrun/mlrun\", requirements=[\"lightgbm\"])\n",
    "\n",
    "fn_remote.add_model(\"lgbm_ny_taxi\", class_name=\"MyReggressor\", model_path=project.get_artifact('lgbm_ny_taxi').uri)\n",
    "\n",
    "remote_addr = fn_remote.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function = project.set_function(name='serving', func='src/serving.py', image='mlrun/mlrun', kind=\"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topology and get the graph object:\n",
    "graph = serving_function.set_topology(\"flow\", engine=\"async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun.feature_store.steps import DateExtractor\n",
    "\n",
    "# Build the serving graph:\n",
    "graph.to(handler=\"add_airport_dist\", name=\"calculate_airport_distance\")\\\n",
    "     .to(handler=\"radian_conv_step\", name=\"calculate_radian_conv\")\\\n",
    "     .to(handler=\"sphere_dist_bear_step\", name=\"bearing_calculation\")\\\n",
    "     .to(handler=\"sphere_dist_step\", name=\"distance_calculation\")\\\n",
    "     .to(DateExtractor(parts=[\"hour\", \"day\", 'month', \"day_of_week\", 'year'],timestamp_col=\"pickup_datetime\"))\\\n",
    "     .to(handler=\"preprocess\", name=\"preprocess\")\\\n",
    "     .to(\"$remote\", remote_func_name, url=f'{remote_addr}v2/models/lgbm_ny_taxi/infer', method='put')\\\n",
    "     .to(handler=\"postprocess\", name=\"postprocess\").respond()\n",
    "\n",
    "# Plot to graph:\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creatresponseock server (in memory simulator for the graph for testing)\n",
    "server = serving_function.to_mock_server()\n",
    "\n",
    "body = {'pickup_longitude':-73.844311, 'pickup_latitude':40.721319,\n",
    "        'dropoff_longitude':-73.84161, 'dropoff_latitude': 40.712278,\n",
    "        'passenger_count':1,\n",
    "        'pickup_datetime': '2013-01-01T12', 'key': '2013-01-01T12'}\n",
    "\n",
    "# simulate a user request and print the results\n",
    "response_mock = server.test(path=\"/v2/models/lgbm_ny_taxi/infer\", body=body.copy())\n",
    "print(response_mock['result_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy-serving\"></a>\n",
    "## Deploy the serving Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy it:\n",
    "deployment = project.deploy_function(serving_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = deployment.function.invoke(path='/predict', body=body.copy())\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert response['result_str'] == response_mock['result_str']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-base",
   "language": "python",
   "name": "conda-env-mlrun-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
